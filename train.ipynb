{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "po40_ifmt8TD"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from time import gmtime, strftime\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,Model\n",
        "from sklearn.model_selection import KFold\n",
        "import gc\n",
        "import time\n",
        "from sklearn.model_selection import KFold\n",
        "import csv\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, matthews_corrcoef, classification_report\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVqCeVjjX-6g",
        "outputId": "09990823-7e17-496c-c2fb-570708ac8ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/drive/MyDrive/s1116049/train_data_A.csv...\t1398/1398\tDone\n",
            "Reading /content/drive/MyDrive/s1116049/test_data_A.csv...\t278/278\tDone\n",
            "Train shape: (1398, 1, 1274, 20)\n",
            "Test shape: (278, 1, 1274, 20)\n",
            "Train label shape: (1398, 1)\n",
            "Test label shape: (278, 1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "MAXSEQ = 1274\n",
        "NUM_FEATURE = 20\n",
        "NUM_FILTER = 128\n",
        "NUM_HIDDEN = 512\n",
        "BATCH_SIZE = 128\n",
        "WINDOW_SIZES = [4,6,8]\n",
        "NUM_CLASSES = 2\n",
        "CLASS_NAMES = ['1', '0']\n",
        "EPOCHS = 50\n",
        "K_FOLD = 5\n",
        "VALIDATION_MODE = \"cross\"\n",
        "\n",
        "def load_ds(file_path):\n",
        "    NUM_SAMPLES = 0\n",
        "    with open(file_path) as file:\n",
        "        NUM_SAMPLES = sum(1 for row in file)\n",
        "\n",
        "    data = np.zeros((NUM_SAMPLES, MAXSEQ * NUM_FEATURE), dtype=np.float32)\n",
        "    labels = np.zeros((NUM_SAMPLES, 1), dtype=np.uint8)\n",
        "\n",
        "    with open(file_path) as file:\n",
        "        file = csv.reader(file, delimiter=',')\n",
        "        m = 0\n",
        "        for row in file:\n",
        "            labels[m] = int(row[0])\n",
        "            data[m] = np.array(row[1:]).astype('float32')\n",
        "            m += 1\n",
        "            print(f\"\\rReading {file_path}...\\t{m}/{NUM_SAMPLES}\", end='')\n",
        "    print('\\tDone')\n",
        "    return data, labels\n",
        "\n",
        "x_train, y_train = load_ds('/content/drive/MyDrive/s1116049/train_data_A.csv')\n",
        "x_test, y_test = load_ds('/content/drive/MyDrive/s1116049/test_data_A.csv')\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = np.reshape(x_train, [-1, 1, MAXSEQ, NUM_FEATURE])\n",
        "x_test = np.reshape(x_test, [-1, 1, MAXSEQ, NUM_FEATURE])\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}\")\n",
        "print(f\"Test shape: {x_test.shape}\")\n",
        "\n",
        "print(f\"Train label shape: {y_train.shape}\")\n",
        "print(f\"Test label shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZtkojDu2YD9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38a2030-f69b-4369-8a24-c33ebb67f8fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 378ms/step - accuracy: 0.5148 - loss: 3.8262\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5399 - loss: 2.1262\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5601 - loss: 1.1395\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5194 - loss: 0.9822\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5132 - loss: 0.8791\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5692 - loss: 0.7579\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5914 - loss: 0.7128\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6202 - loss: 0.6694\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6240 - loss: 0.6532\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.6244 - loss: 0.6744\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6452 - loss: 0.6439\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6646 - loss: 0.6066\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6798 - loss: 0.5921\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.6963 - loss: 0.5649\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.6733 - loss: 0.6031\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.7091 - loss: 0.5538\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7583 - loss: 0.4917\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7652 - loss: 0.4959\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7558 - loss: 0.4870\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7830 - loss: 0.4467\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7955 - loss: 0.4323\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7875 - loss: 0.4361\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8104 - loss: 0.4040\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8325 - loss: 0.3641\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8222 - loss: 0.3804\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8665 - loss: 0.3355\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8578 - loss: 0.3299\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8752 - loss: 0.2962\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8916 - loss: 0.2847\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8610 - loss: 0.2951\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8859 - loss: 0.2748\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9137 - loss: 0.2334\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8878 - loss: 0.2519\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9040 - loss: 0.2275\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9114 - loss: 0.2155\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9435 - loss: 0.1766\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9487 - loss: 0.1638\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9382 - loss: 0.1663\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9299 - loss: 0.1696\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9450 - loss: 0.1422\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9444 - loss: 0.1415\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9437 - loss: 0.1520\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9419 - loss: 0.1476\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9567 - loss: 0.1124\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9599 - loss: 0.1159\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9693 - loss: 0.1062\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9710 - loss: 0.0833\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9690 - loss: 0.1028\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9769 - loss: 0.0834\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9738 - loss: 0.0875\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n",
            "\n",
            "Fold 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.85      0.87       131\n",
            "           1       0.88      0.91      0.89       149\n",
            "\n",
            "    accuracy                           0.88       280\n",
            "   macro avg       0.88      0.88      0.88       280\n",
            "weighted avg       0.88      0.88      0.88       280\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 305ms/step - accuracy: 0.4815 - loss: 4.1566\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5471 - loss: 2.1418\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5334 - loss: 1.2340\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5026 - loss: 1.0804\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5920 - loss: 0.8072\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5748 - loss: 0.7394\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5848 - loss: 0.7182\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5806 - loss: 0.7386\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6018 - loss: 0.7013\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6114 - loss: 0.6623\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6397 - loss: 0.6483\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6562 - loss: 0.6138\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6232 - loss: 0.6304\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6462 - loss: 0.6190\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6696 - loss: 0.5997\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7086 - loss: 0.5650\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7077 - loss: 0.5539\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7171 - loss: 0.5410\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7591 - loss: 0.4964\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7813 - loss: 0.4506\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7751 - loss: 0.4803\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8029 - loss: 0.4268\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7893 - loss: 0.4345\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8190 - loss: 0.3997\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8095 - loss: 0.4097\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8369 - loss: 0.3641\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8456 - loss: 0.3546\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.8606 - loss: 0.3308\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8681 - loss: 0.3169\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8576 - loss: 0.3256\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8541 - loss: 0.3148\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8703 - loss: 0.3042\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9100 - loss: 0.2396\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9183 - loss: 0.2271\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9141 - loss: 0.2379\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9420 - loss: 0.1754\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9257 - loss: 0.1896\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9525 - loss: 0.1554\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9480 - loss: 0.1621\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9523 - loss: 0.1479\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9434 - loss: 0.1483\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9372 - loss: 0.1472\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9557 - loss: 0.1408\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9715 - loss: 0.1171\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9644 - loss: 0.1133\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9665 - loss: 0.1058\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9683 - loss: 0.0933\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9723 - loss: 0.0840\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9750 - loss: 0.0814\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9671 - loss: 0.0976\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\n",
            "Fold 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.98      0.90       130\n",
            "           1       0.98      0.82      0.89       150\n",
            "\n",
            "    accuracy                           0.90       280\n",
            "   macro avg       0.90      0.90      0.90       280\n",
            "weighted avg       0.91      0.90      0.90       280\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 257ms/step - accuracy: 0.4933 - loss: 2.6784\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5077 - loss: 2.0537\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5391 - loss: 1.0629\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5989 - loss: 0.8361\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5744 - loss: 0.8575\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5614 - loss: 0.8309\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5909 - loss: 0.7449\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5867 - loss: 0.7285\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6437 - loss: 0.6618\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6430 - loss: 0.6471\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6730 - loss: 0.6222\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6930 - loss: 0.5778\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6861 - loss: 0.5768\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7121 - loss: 0.5490\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7388 - loss: 0.5079\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7450 - loss: 0.4997\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7850 - loss: 0.4603\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7866 - loss: 0.4493\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7918 - loss: 0.4387\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8439 - loss: 0.3821\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7958 - loss: 0.4320\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8289 - loss: 0.3717\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8246 - loss: 0.3628\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8478 - loss: 0.3408\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8523 - loss: 0.3259\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8789 - loss: 0.2917\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8897 - loss: 0.2717\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8894 - loss: 0.2759\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8894 - loss: 0.2757\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9015 - loss: 0.2495\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8832 - loss: 0.2631\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8785 - loss: 0.2766\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9125 - loss: 0.2209\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9363 - loss: 0.1760\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9392 - loss: 0.1761\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9328 - loss: 0.1790\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9465 - loss: 0.1611\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9491 - loss: 0.1436\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9470 - loss: 0.1505\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9489 - loss: 0.1402\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9514 - loss: 0.1280\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9527 - loss: 0.1315\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9609 - loss: 0.1225\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9630 - loss: 0.1066\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9624 - loss: 0.1236\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9592 - loss: 0.1227\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9546 - loss: 0.1185\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9793 - loss: 0.0826\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9735 - loss: 0.0869\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9841 - loss: 0.0677\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Fold 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       109\n",
            "           1       0.92      0.89      0.91       171\n",
            "\n",
            "    accuracy                           0.89       280\n",
            "   macro avg       0.88      0.88      0.88       280\n",
            "weighted avg       0.89      0.89      0.89       280\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 395ms/step - accuracy: 0.5033 - loss: 2.6923\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.4986 - loss: 1.5484\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5539 - loss: 1.0694\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5669 - loss: 0.8294\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5480 - loss: 0.8152\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5986 - loss: 0.7034\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5500 - loss: 0.7337\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5601 - loss: 0.7202\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.6031 - loss: 0.6757\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6079 - loss: 0.6685\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6239 - loss: 0.6557\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6357 - loss: 0.6429\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6705 - loss: 0.6054\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6626 - loss: 0.6082\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6850 - loss: 0.5760\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7480 - loss: 0.5218\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7487 - loss: 0.5171\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7538 - loss: 0.4967\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.7656 - loss: 0.4885\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7773 - loss: 0.4429\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7936 - loss: 0.4500\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8235 - loss: 0.3905\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8494 - loss: 0.3602\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8028 - loss: 0.4194\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8740 - loss: 0.3265\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8696 - loss: 0.3196\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8952 - loss: 0.3056\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9068 - loss: 0.2613\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8786 - loss: 0.2838\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9075 - loss: 0.2360\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9080 - loss: 0.2248\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9297 - loss: 0.2042\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9223 - loss: 0.2176\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9461 - loss: 0.1600\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9188 - loss: 0.1994\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9429 - loss: 0.1613\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9291 - loss: 0.1639\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9437 - loss: 0.1661\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9511 - loss: 0.1384\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9425 - loss: 0.1576\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9454 - loss: 0.1390\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9621 - loss: 0.1119\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9691 - loss: 0.0966\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9800 - loss: 0.0846\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9633 - loss: 0.1002\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9738 - loss: 0.0807\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9699 - loss: 0.0904\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9706 - loss: 0.0793\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9871 - loss: 0.0646\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9712 - loss: 0.0824\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
            "\n",
            "Fold 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.82      0.85       120\n",
            "           1       0.87      0.92      0.90       159\n",
            "\n",
            "    accuracy                           0.88       279\n",
            "   macro avg       0.88      0.87      0.87       279\n",
            "weighted avg       0.88      0.88      0.88       279\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 264ms/step - accuracy: 0.4794 - loss: 3.5612\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5401 - loss: 1.6869\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.5485 - loss: 1.1210\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5454 - loss: 0.8474\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5560 - loss: 0.7700\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6072 - loss: 0.6845\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5894 - loss: 0.7083\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6430 - loss: 0.6565\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6079 - loss: 0.6748\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5951 - loss: 0.6709\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6205 - loss: 0.6640\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6481 - loss: 0.6381\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6991 - loss: 0.5951\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6850 - loss: 0.5756\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6936 - loss: 0.5622\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7078 - loss: 0.5438\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7580 - loss: 0.5102\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7291 - loss: 0.5075\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7689 - loss: 0.4834\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.7780 - loss: 0.4595\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8325 - loss: 0.3878\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8297 - loss: 0.4038\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8226 - loss: 0.4042\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8409 - loss: 0.3642\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8669 - loss: 0.3203\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8559 - loss: 0.3382\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8540 - loss: 0.3045\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8632 - loss: 0.2990\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8721 - loss: 0.3071\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9160 - loss: 0.2463\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9154 - loss: 0.2381\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9211 - loss: 0.2179\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9333 - loss: 0.2042\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9323 - loss: 0.1885\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9248 - loss: 0.2043\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9259 - loss: 0.1923\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9340 - loss: 0.1657\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9507 - loss: 0.1496\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9461 - loss: 0.1528\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9594 - loss: 0.1146\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9489 - loss: 0.1249\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9503 - loss: 0.1260\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9546 - loss: 0.1212\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9643 - loss: 0.0996\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9604 - loss: 0.1096\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9711 - loss: 0.0906\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9682 - loss: 0.0918\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9711 - loss: 0.0825\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9742 - loss: 0.0768\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9781 - loss: 0.0761\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\n",
            "Fold 5 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.81      0.84       131\n",
            "           1       0.84      0.91      0.87       148\n",
            "\n",
            "    accuracy                           0.86       279\n",
            "   macro avg       0.86      0.86      0.86       279\n",
            "weighted avg       0.86      0.86      0.86       279\n",
            "\n",
            "Mean AUC: 0.9502\n",
            "Aggregated Metrics:\n",
            "  TP=138, FP=16, TN=108, FN=17\n",
            "  Sens=0.8889, Spec=0.8691, Acc=0.8805, MCC=0.7606, AUC=0.9498, F1=0.8919\n",
            "Epoch 1/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.5075 - loss: 3.7438\n",
            "Epoch 2/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5296 - loss: 1.4686\n",
            "Epoch 3/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5298 - loss: 1.0306\n",
            "Epoch 4/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5284 - loss: 0.8798\n",
            "Epoch 5/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5627 - loss: 0.7427\n",
            "Epoch 6/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5622 - loss: 0.7308\n",
            "Epoch 7/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6066 - loss: 0.6678\n",
            "Epoch 8/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6057 - loss: 0.6775\n",
            "Epoch 9/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6188 - loss: 0.6705\n",
            "Epoch 10/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6359 - loss: 0.6433\n",
            "Epoch 11/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6686 - loss: 0.6027\n",
            "Epoch 12/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7010 - loss: 0.5771\n",
            "Epoch 13/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7113 - loss: 0.5768\n",
            "Epoch 14/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7287 - loss: 0.5382\n",
            "Epoch 15/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7531 - loss: 0.4967\n",
            "Epoch 16/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7773 - loss: 0.4641\n",
            "Epoch 17/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8106 - loss: 0.4346\n",
            "Epoch 18/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7965 - loss: 0.4248\n",
            "Epoch 19/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7942 - loss: 0.4371\n",
            "Epoch 20/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8314 - loss: 0.3721\n",
            "Epoch 21/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8293 - loss: 0.3681\n",
            "Epoch 22/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8640 - loss: 0.3144\n",
            "Epoch 23/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8814 - loss: 0.2839\n",
            "Epoch 24/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8789 - loss: 0.2975\n",
            "Epoch 25/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8815 - loss: 0.2800\n",
            "Epoch 26/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9090 - loss: 0.2474\n",
            "Epoch 27/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9333 - loss: 0.2025\n",
            "Epoch 28/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9164 - loss: 0.2137\n",
            "Epoch 29/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9116 - loss: 0.2068\n",
            "Epoch 30/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9275 - loss: 0.1893\n",
            "Epoch 31/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9414 - loss: 0.1782\n",
            "Epoch 32/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9376 - loss: 0.1710\n",
            "Epoch 33/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9218 - loss: 0.1736\n",
            "Epoch 34/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9585 - loss: 0.1227\n",
            "Epoch 35/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9612 - loss: 0.1254\n",
            "Epoch 36/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9607 - loss: 0.1253\n",
            "Epoch 37/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9459 - loss: 0.1455\n",
            "Epoch 38/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9533 - loss: 0.1217\n",
            "Epoch 39/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9735 - loss: 0.0908\n",
            "Epoch 40/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9627 - loss: 0.1176\n",
            "Epoch 41/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9663 - loss: 0.0986\n",
            "Epoch 42/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9687 - loss: 0.1011\n",
            "Epoch 43/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9755 - loss: 0.0853\n",
            "Epoch 44/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9433 - loss: 0.1348\n",
            "Epoch 45/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9492 - loss: 0.1181\n",
            "Epoch 46/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9584 - loss: 0.1146\n",
            "Epoch 47/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9728 - loss: 0.0771\n",
            "Epoch 48/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9716 - loss: 0.0870\n",
            "Epoch 49/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9739 - loss: 0.0835\n",
            "Epoch 50/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9793 - loss: 0.0683\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
            "\n",
            "Final Model Test Metrics:\n",
            "  TP=114, FP=18, TN=138, FN=8\n",
            "  Sens=0.9344, Spec=0.8846, Acc=0.9065, MCC=0.8139, F1=0.8976\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.91       156\n",
            "           1       0.86      0.93      0.90       122\n",
            "\n",
            "    accuracy                           0.91       278\n",
            "   macro avg       0.90      0.91      0.91       278\n",
            "weighted avg       0.91      0.91      0.91       278\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import layers, Model\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, matthews_corrcoef\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def build_model(input_shape, window_sizes, num_filters, num_hidden):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    conv_layers = []\n",
        "    for window_size in window_sizes:\n",
        "        conv = layers.Conv2D(filters=num_filters, kernel_size=(1, window_size), activation='relu', padding='valid')(inputs)\n",
        "        pool = layers.MaxPooling2D(pool_size=(1, input_shape[1] - window_size + 1), strides=(1, input_shape[1]), padding='valid')(conv)\n",
        "        flat = layers.Flatten()(pool)\n",
        "        conv_layers.append(flat)\n",
        "    x = layers.Concatenate()(conv_layers)\n",
        "    x = layers.Dropout(rate=0.6)(x)\n",
        "    x = layers.Dense(num_hidden, activation='relu')(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Cross-validation on training data\n",
        "metrics_summary = {'TP': [], 'FP': [], 'TN': [], 'FN': [], 'Sens': [], 'Spec': [], 'Acc': [], 'MCC': [], 'AUC': [], 'F1': []}\n",
        "roc_values = {'fpr': [], 'tpr': [], 'auc': []}\n",
        "\n",
        "kfold = KFold(n_splits=K_FOLD, shuffle=True, random_state=42)  # Enable shuffling\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kfold.split(x_train)):\n",
        "    X_train_fold, X_val_fold = x_train[train_index], x_train[val_index]\n",
        "    Y_train_fold, Y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    model = build_model(input_shape=(1, MAXSEQ, NUM_FEATURE), window_sizes=WINDOW_SIZES, num_filters=NUM_FILTER, num_hidden=NUM_HIDDEN)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train_fold, Y_train_fold, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, shuffle=True)  # Enable shuffling\n",
        "\n",
        "    Y_val_pred = model.predict(X_val_fold).flatten()\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(Y_val_fold, Y_val_pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    roc_values['fpr'].append(fpr.tolist())\n",
        "    roc_values['tpr'].append(tpr.tolist())\n",
        "    roc_values['auc'].append(roc_auc)\n",
        "    metrics_summary['AUC'].append(roc_auc)\n",
        "\n",
        "    Y_val_pred_binary = (Y_val_pred > 0.5).astype(int)\n",
        "    cm = confusion_matrix(Y_val_fold, Y_val_pred_binary)\n",
        "    TP = cm[1, 1]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "    TN = cm[0, 0]\n",
        "\n",
        "    metrics_summary['TP'].append(TP)\n",
        "    metrics_summary['FP'].append(FP)\n",
        "    metrics_summary['TN'].append(TN)\n",
        "    metrics_summary['FN'].append(FN)\n",
        "    metrics_summary['Sens'].append(TP / (TP + FN) if (TP + FN) else 0)\n",
        "    metrics_summary['Spec'].append(TN / (TN + FP) if (TN + FP) else 0)\n",
        "    metrics_summary['Acc'].append((TP + TN) / cm.sum())\n",
        "    metrics_summary['MCC'].append(matthews_corrcoef(Y_val_fold, Y_val_pred_binary) if (TP + FP) * (TP + FN) * (TN + FP) * (TN + FN) else 0)\n",
        "    metrics_summary['F1'].append(2 * TP / (2 * TP + FP + FN) if (2 * TP + FP + FN) else 0)\n",
        "\n",
        "    print(f\"\\nFold {fold + 1} Classification Report:\")\n",
        "    print(classification_report(Y_val_fold, Y_val_pred_binary))\n",
        "\n",
        "# Calculate mean ROC values\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "tpr_interp_list = [np.interp(mean_fpr, fpr, tpr) for fpr, tpr in zip(roc_values['fpr'], roc_values['tpr'])]\n",
        "mean_tpr = np.mean(tpr_interp_list, axis=0)\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "\n",
        "print(f\"Mean AUC: {mean_auc:.4f}\")\n",
        "\n",
        "print(\"Aggregated Metrics:\")\n",
        "print(f\"  TP={np.mean(metrics_summary['TP']):.0f}, FP={np.mean(metrics_summary['FP']):.0f}, TN={np.mean(metrics_summary['TN']):.0f}, FN={np.mean(metrics_summary['FN']):.0f}\")\n",
        "print(f\"  Sens={np.mean(metrics_summary['Sens']):.4f}, Spec={np.mean(metrics_summary['Spec']):.4f}, Acc={np.mean(metrics_summary['Acc']):.4f}, MCC={np.mean(metrics_summary['MCC']):.4f}, AUC={np.mean(metrics_summary['AUC']):.4f}, F1={np.mean(metrics_summary['F1']):.4f}\")\n",
        "\n",
        "# Final model training on entire training data\n",
        "final_model = build_model(input_shape=(1, MAXSEQ, NUM_FEATURE), window_sizes=WINDOW_SIZES, num_filters=NUM_FILTER, num_hidden=NUM_HIDDEN)\n",
        "final_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "final_model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, shuffle=True)  # Enable shuffling\n",
        "\n",
        "# Evaluate the final model on the test data\n",
        "y_test_pred = final_model.predict(x_test).flatten()\n",
        "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
        "cm_test = confusion_matrix(y_test, y_test_pred_binary)\n",
        "tp_test = cm_test[1, 1]\n",
        "fp_test = cm_test[0, 1]\n",
        "fn_test = cm_test[1, 0]\n",
        "tn_test = cm_test[0, 0]\n",
        "\n",
        "test_sens = tp_test / (tp_test + fn_test) if (tp_test + fn_test) else 0\n",
        "test_spec = tn_test / (tn_test + fp_test) if (tn_test + fp_test) else 0\n",
        "test_acc = (tp_test + tn_test) / cm_test.sum()\n",
        "test_mcc = matthews_corrcoef(y_test, y_test_pred_binary) if (tp_test + fp_test) * (tp_test + fn_test) * (tn_test + fp_test) * (tn_test + fn_test) else 0\n",
        "test_f1 = 2 * tp_test / (2 * tp_test + fp_test + fn_test) if (2 * tp_test + fp_test + fn_test) else 0\n",
        "\n",
        "print(\"\\nFinal Model Test Metrics:\")\n",
        "print(f\"  TP={tp_test}, FP={fp_test}, TN={tn_test}, FN={fn_test}\")\n",
        "print(f\"  Sens={test_sens:.4f}, Spec={test_spec:.4f}, Acc={test_acc:.4f}, MCC={test_mcc:.4f}, F1={test_f1:.4f}\")\n",
        "print(classification_report(y_test, y_test_pred_binary))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "import math\n",
        "\n",
        "# Define constants\n",
        "MAXSEQ = 1274\n",
        "NUM_FEATURE = 20\n",
        "NUM_FILTER = 128\n",
        "NUM_HIDDEN = 512\n",
        "BATCH_SIZE = 128\n",
        "WINDOW_SIZES = [2,4,6]\n",
        "CLASS_NAMES = ['1', '0']\n",
        "EPOCHS = 50\n",
        "VALIDATION_MODE = \"independent\"\n",
        "NUM_CLASSES = 2\n",
        "# Load dataset function\n",
        "def load_ds(file_path):\n",
        "    NUM_SAMPLES = 0\n",
        "    with open(file_path) as file:\n",
        "        NUM_SAMPLES = sum(1 for row in file)\n",
        "\n",
        "    data = np.zeros((NUM_SAMPLES, MAXSEQ * NUM_FEATURE), dtype=np.float32)\n",
        "    labels = np.zeros((NUM_SAMPLES, 1), dtype=np.uint8)\n",
        "\n",
        "    with open(file_path) as file:\n",
        "        file = csv.reader(file, delimiter=',')\n",
        "        m = 0\n",
        "        for row in file:\n",
        "            labels[m] = int(row[0])\n",
        "            data[m] = np.array(row[1:]).astype('float32')\n",
        "            m += 1\n",
        "            print(f\"\\rReading {file_path}...\\t{m}/{NUM_SAMPLES}\", end='')\n",
        "    print('\\tDone')\n",
        "    return data, labels\n",
        "\n",
        "# Load training and testing data\n",
        "x_train, y_train = load_ds('/content/drive/MyDrive/s1116049/train_data_A.csv')\n",
        "x_test, y_test = load_ds('/content/drive/MyDrive/s1116049/test_data_A.csv')\n",
        "\n",
        "# Reshape data to add channels dimension\n",
        "x_train = np.reshape(x_train, [-1, 1, MAXSEQ, NUM_FEATURE])\n",
        "x_test = np.reshape(x_test, [-1, 1, MAXSEQ, NUM_FEATURE])\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}\")\n",
        "print(f\"Test shape: {x_test.shape}\")\n",
        "print(f\"Train label shape: {y_train.shape}\")\n",
        "print(f\"Test label shape: {y_test.shape}\")\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=NUM_CLASSES)\n",
        "\n",
        "class DeepScan(Model):\n",
        "    def __init__(self, input_shape=(1, MAXSEQ, NUM_FEATURE), window_sizes=[2,4,6], num_filters=256, num_hidden=512):\n",
        "        super(DeepScan, self).__init__()\n",
        "\n",
        "        # Initialize layers\n",
        "        self.window_sizes = window_sizes\n",
        "        self.conv_layers = []\n",
        "        self.pool_layers = []\n",
        "        self.flatten_layers = []\n",
        "\n",
        "        # Create corresponding convolution, pooling, and flatten layers for each window size\n",
        "        for window_size in self.window_sizes:\n",
        "            self.conv_layers.append(\n",
        "                layers.Conv2D(filters=num_filters,\n",
        "                              kernel_size=(1, window_size),\n",
        "                              activation='relu',\n",
        "                              padding='valid')\n",
        "            )\n",
        "            self.pool_layers.append(\n",
        "                layers.MaxPooling2D(pool_size=(1, MAXSEQ - window_size + 1),\n",
        "                                    strides=(1, MAXSEQ),\n",
        "                                    padding='valid')\n",
        "            )\n",
        "            self.flatten_layers.append(layers.Flatten())\n",
        "\n",
        "        # Define fully connected layers\n",
        "        self.dropout = layers.Dropout(rate=0.5)\n",
        "        self.fc1 = layers.Dense(num_hidden, activation='relu')\n",
        "        self.fc2 = layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(1e-3))\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        # Apply convolution, pooling, and flatten operations\n",
        "        x_list = []\n",
        "        for i in range(len(self.window_sizes)):\n",
        "            x_conv = self.conv_layers[i](x)\n",
        "            x_pool = self.pool_layers[i](x_conv)\n",
        "            x_flat = self.flatten_layers[i](x_pool)\n",
        "            x_list.append(x_flat)\n",
        "\n",
        "        # Concatenate all outputs\n",
        "        x = tf.concat(x_list, axis=1)\n",
        "\n",
        "        # Apply dropout, fully connected, and output layers\n",
        "        x = self.dropout(x, training=training)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def model_test(model, x_test, y_test):\n",
        "    # Generate predictions\n",
        "    pred_test = model.predict(x_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    fpr, tpr, thresholds = roc_curve(y_test[:, 1], pred_test[:, 1])\n",
        "    AUC = metrics.auc(fpr, tpr)\n",
        "    display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=AUC, estimator_name='mCNN')\n",
        "    display.plot()\n",
        "\n",
        "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
        "    ix = np.argmax(gmeans)\n",
        "    print(f'\\nBest Threshold={thresholds[ix]}, G-Mean={gmeans[ix]}')\n",
        "    threshold = thresholds[ix]\n",
        "    y_pred = (pred_test[:, 1] >= threshold).astype(int)\n",
        "\n",
        "    TN, FP, FN, TP = metrics.confusion_matrix(y_test[:, 1], y_pred).ravel()\n",
        "    Sens = TP / (TP + FN) if TP + FN > 0 else 0.0\n",
        "    Spec = TN / (FP + TN) if FP + TN > 0 else 0.0\n",
        "    Acc = (TP + TN) / (TP + FP + TN + FN)\n",
        "    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) if TP + FP > 0 and FP + TN > 0 and TP + FN > 0 and TN + FN > 0 else 0.0\n",
        "    F1 = 2 * TP / (2 * TP + FP + FN)\n",
        "    Prec = TP / (TP + FP)\n",
        "    Recall = TP / (TP + FN)\n",
        "\n",
        "    print(f'TP={TP}, FP={FP}, TN={TN}, FN={FN}, Sens={Sens:.4f}, Spec={Spec:.4f}, Acc={Acc:.4f}, MCC={MCC:.4f}, AUC={AUC:.4f}, F1={F1:.4f}, Prec={Prec:.4f}, Recall={Recall:.4f}\\n')\n",
        "\n",
        "    return TP, FP, TN, FN, Sens, Spec, Acc, MCC, AUC, F1, Prec, Recall\n",
        "\n",
        "if VALIDATION_MODE == \"independent\":\n",
        "    # Initialize the DeepScan model\n",
        "    model = DeepScan(\n",
        "        input_shape=(1, MAXSEQ, NUM_FEATURE),\n",
        "        num_filters=NUM_FILTER,\n",
        "        num_hidden=NUM_HIDDEN,\n",
        "        window_sizes=WINDOW_SIZES\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    # Test the model\n",
        "    TP, FP, TN, FN, Sens, Spec, Acc, MCC, AUC, F1, Prec, Recall = model_test(model, x_test, y_test)\n"
      ],
      "metadata": {
        "id": "I7jj2L6EDtwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0695c820-13b3-409c-8559-8e54f0b738de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/drive/MyDrive/s1116049/train_data_A.csv...\t1398/1398\tDone\n",
            "Reading /content/drive/MyDrive/s1116049/test_data_A.csv...\t278/278\tDone\n",
            "Train shape: (1398, 1, 1274, 20)\n",
            "Test shape: (278, 1, 1274, 20)\n",
            "Train label shape: (1398, 1)\n",
            "Test label shape: (278, 1)\n",
            "Epoch 1/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.5115 - loss: 4.3477\n",
            "Epoch 2/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5047 - loss: 1.5991\n",
            "Epoch 3/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5409 - loss: 1.0490\n",
            "Epoch 4/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5717 - loss: 0.8287\n",
            "Epoch 5/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5760 - loss: 0.7709\n",
            "Epoch 6/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.5919 - loss: 0.7522\n",
            "Epoch 7/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6188 - loss: 0.6943\n",
            "Epoch 8/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6370 - loss: 0.6695\n",
            "Epoch 9/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6361 - loss: 0.6621\n",
            "Epoch 10/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6756 - loss: 0.6249\n",
            "Epoch 11/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6871 - loss: 0.5993\n",
            "Epoch 12/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7010 - loss: 0.5802\n",
            "Epoch 13/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7062 - loss: 0.5811\n",
            "Epoch 14/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7148 - loss: 0.5476\n",
            "Epoch 15/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7136 - loss: 0.5549\n",
            "Epoch 16/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7149 - loss: 0.5427\n",
            "Epoch 17/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7337 - loss: 0.5259\n",
            "Epoch 18/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7537 - loss: 0.4911\n",
            "Epoch 19/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.7733 - loss: 0.4821\n",
            "Epoch 20/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.7782 - loss: 0.4569\n",
            "Epoch 21/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8160 - loss: 0.4268\n",
            "Epoch 22/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.7873 - loss: 0.4478\n",
            "Epoch 23/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8291 - loss: 0.3952\n",
            "Epoch 24/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8383 - loss: 0.3839\n",
            "Epoch 25/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8393 - loss: 0.3676\n",
            "Epoch 26/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.8332 - loss: 0.3633\n",
            "Epoch 27/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8660 - loss: 0.3195\n",
            "Epoch 28/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8658 - loss: 0.3294\n",
            "Epoch 29/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8515 - loss: 0.3349\n",
            "Epoch 30/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8916 - loss: 0.2747\n",
            "Epoch 31/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8771 - loss: 0.2849\n",
            "Epoch 32/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8943 - loss: 0.2492\n",
            "Epoch 33/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8995 - loss: 0.2446\n",
            "Epoch 34/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8746 - loss: 0.2857\n",
            "Epoch 35/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8946 - loss: 0.2570\n",
            "Epoch 36/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9083 - loss: 0.2218\n",
            "Epoch 37/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9078 - loss: 0.2339\n",
            "Epoch 38/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9399 - loss: 0.1685\n",
            "Epoch 39/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9366 - loss: 0.1863\n",
            "Epoch 40/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9252 - loss: 0.1789\n",
            "Epoch 41/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9533 - loss: 0.1467\n",
            "Epoch 42/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9336 - loss: 0.1892\n",
            "Epoch 43/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9328 - loss: 0.1528\n",
            "Epoch 44/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9368 - loss: 0.1595\n",
            "Epoch 45/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9555 - loss: 0.1332\n",
            "Epoch 46/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9212 - loss: 0.1812\n",
            "Epoch 47/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9598 - loss: 0.1312\n",
            "Epoch 48/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9657 - loss: 0.1132\n",
            "Epoch 49/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9662 - loss: 0.1078\n",
            "Epoch 50/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9663 - loss: 0.1035\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\n",
            "Best Threshold=0.581188976764679, G-Mean=0.9132449799712139\n",
            "TP=111, FP=13, TN=143, FN=11, Sens=0.9098, Spec=0.9167, Acc=0.9137, MCC=0.8251, AUC=0.9727, F1=0.9024, Prec=0.8952, Recall=0.9098\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+iUlEQVR4nO3df3zN9f//8fvZ7OwHNjQ2YxqKyK8QH9RbskxK9MuKN6PSL8PbUn7/TKYfxFtq70TDVxGpFM07pJASs37RhEl+bCwxP7c55/X9o8vOu7WNnTlnZ3vtdr1cXpeL8zyv1+s8Xi/j3Pd8Pl+vl8UwDEMAAAAm4eXpAgAAAFyJcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEylkqcLKG12u11Hjx5V1apVZbFYPF0OAAAoBsMwdObMGYWFhcnL6/J9MxUu3Bw9elTh4eGeLgMAAJTAb7/9prp16152nQoXbqpWrSrpz5MTGBjo4WoAAEBxZGVlKTw83PE9fjkVLtzkDUUFBgYSbgAAKGeKM6WECcUAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUPBpuvvzyS/Xs2VNhYWGyWCz68MMPr7jNpk2b1Lp1a/n6+uq6665TYmKi2+sEAADlh0fDzblz59SyZUvNmzevWOunpaXprrvuUpcuXZSSkqJ//etfeuyxx7Ru3To3VwoAAMoLjz44884779Sdd95Z7PUTEhJUv359zZw5U5LUpEkTbdmyRa+++qqioqLcVSaAcsgwDF3ItXm6DKDC8vfxLtZDLt2hXD0VfNu2bYqMjMzXFhUVpX/9619FbpOdna3s7GzH66ysLHeVB6CMMAxDDyRs085f//B0KUCFtXtqlAKsnokZ5WpCcXp6ukJCQvK1hYSEKCsrSxcuXCh0m/j4eAUFBTmW8PDw0igVgAddyLURbIAKrFz13JTEmDFjFBcX53idlZVFwEGZwdCJe5zP+d853TE+UgFWbw9WA1RM/j6e+3dXrsJNaGioMjIy8rVlZGQoMDBQ/v7+hW7j6+srX1/f0igPcApDJ6UjwOrtsa5xAJ5Rrv7Fd+jQQWvXrs3X9tlnn6lDhw4eqgj4U0l6YM7nMHTibm2vre7R3x4BeIZHw83Zs2e1b98+x+u0tDSlpKSoRo0aqlevnsaMGaMjR45o8eLFkqQnn3xSr732mp577jk98sgj2rhxo9577z2tWbPGU4cAuKQHhqET9/Dk1RoAPMej4WbHjh3q0qWL43Xe3JiYmBglJibq2LFjOnTokOP9+vXra82aNRoxYoTmzJmjunXr6q233uIycHjU1U5ebXttdV1T2cqXMAC4iMUwDMPTRZSmrKwsBQUF6fTp0woMDPR0OShjSjq81Hbaekkl64GhdwEArsyZ7+9yNecGcCdXDC8xeRUAPK9c3ecGcCdXDC8xeRUAPI9fMeFy5fXeLVd7bxSGlwCgbCDcwKXMcu8WhpcAoPxiWAouZYbb3jO8BADlG7+a4qr8fQjKDLe9Z3gJAMo3wg1K7EpDUAztAAA8gW8eOC2vt+Zyjw9gaAcA4CmEGzilqN6avw9BMbQDAPAUwg2cUtiEYR4fAAAoSwg3KLG83hp6aQAAZQnhBiXGhGEAQFnEfW4AAICp8Gs38rnSoxP+eh8bAADKIsINHMzy6AQAQMXGsBQcnHl0AvexAQCUVfTcIN9N+fJc6dEJXCEFACirCDcVXFFDUVwJBQAorxiWquCKuikfQ04AgPKKX83hwE35AABmQLiBA0NRAAAz4JvM5LhvDQCgoiHcmBj3rQEAVERMKDYx7lsDAKiI6LmpILhvDQCgoiDcVBBMFgYAVBQMSwEAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFPhSYpljGEYupBrc8m+zue4Zj8AAJQnhJsyxDAMPZCwTTt//cPTpQAAUG4xLFWGXMi1uSXYtL22uvx9vF2+XwAAyiJ6bsqoHeMjFWB1TSDx9/GWxWJxyb4AACjrCDdlVIDVWwFW/noAAHAWw1IAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUPB5u5s2bp4iICPn5+al9+/bavn37ZdefPXu2GjduLH9/f4WHh2vEiBG6ePFiKVXrHoZh6HzOJZ3PsXm6FAAAyr1Knvzw5cuXKy4uTgkJCWrfvr1mz56tqKgopaamqlatWgXWf+eddzR69GgtXLhQHTt21N69ezVw4EBZLBbNmjXLA0dw9QzD0AMJ27Tz1z88XQoAAKbg0Z6bWbNmafDgwRo0aJCaNm2qhIQEBQQEaOHChYWu/9VXX6lTp07q27evIiIi1K1bNz388MOX7e3Jzs5WVlZWvqUsuZBrKxBs2l5bXf4+3h6qCACA8s1j4SYnJ0c7d+5UZGTk/4rx8lJkZKS2bdtW6DYdO3bUzp07HWHmwIEDWrt2rXr06FHk58THxysoKMixhIeHu/ZAXGjH+EjtnhqlFU92kMVi8XQ5AACUSx4blsrMzJTNZlNISEi+9pCQEP3888+FbtO3b19lZmbqlltukWEYunTpkp588kmNHTu2yM8ZM2aM4uLiHK+zsrLKbMAJsHorwOrRkUIAAMo9j08odsamTZs0ffp0vf7660pOTtaqVau0Zs0aPf/880Vu4+vrq8DAwHwLAAAwL491EwQHB8vb21sZGRn52jMyMhQaGlroNhMmTFD//v312GOPSZKaN2+uc+fO6fHHH9e4cePk5VWushoAAHADj6UBq9WqNm3aaMOGDY42u92uDRs2qEOHDoVuc/78+QIBxtv7z4m3hmG4r1gAAFBueHSCR1xcnGJiYtS2bVu1a9dOs2fP1rlz5zRo0CBJ0oABA1SnTh3Fx8dLknr27KlZs2bppptuUvv27bVv3z5NmDBBPXv2dIQcAABQsXk03ERHR+vEiROaOHGi0tPT1apVKyUlJTkmGR86dChfT8348eNlsVg0fvx4HTlyRDVr1lTPnj31wgsveOoQAABAGWMxKth4TlZWloKCgnT69OkyMbn4fM4lNZ24TpK0e2oUV0sBAFAIZ76/+Sb1EMMwdCHXxiMXAABwMcKNB/DIBQAA3Idrpz2ARy4AAOA+9Nx42I7xkQqwesvfx5tHLgAA4AKEGw/jkQsAALgWw1IAAMBU6DIoBXlXRuXhCikAANyHcONmXBkFAEDpYljKzQq7MioPV0gBAOB69NyUorwro/JwhRQAAK5HuClFXBkFAID7MSwFAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABM5arCzcWLF11Vh+kYhqHzOZd0Psfm6VIAAKhQnA43drtdzz//vOrUqaMqVarowIEDkqQJEyZowYIFLi+wPDIMQw8kbFPTievUdtp6T5cDAECF4nS4mTZtmhITE/XSSy/JarU62ps1a6a33nrLpcWVVxdybdr56x/52tpeW13+Pt4eqggAgIqjkrMbLF68WG+++aa6du2qJ5980tHesmVL/fzzzy4tzgx2jI9UgNVb/j7eslgsni4HAADTczrcHDlyRNddd12BdrvdrtzcXJcUZSYBVm8FWJ0+zQAAoIScHpZq2rSpNm/eXKB95cqVuummm1xSFAAAQEk53aUwceJExcTE6MiRI7Lb7Vq1apVSU1O1ePFiffLJJ+6oEQAAoNic7rnp1auXPv74Y61fv16VK1fWxIkTtWfPHn388ce644473FEjAABAsZVoMsitt96qzz77zNW1AAAAXDWne24aNGig33//vUD7qVOn1KBBA5cUBQAAUFJOh5uDBw/KZit4193s7GwdOXLEJUUBAACUVLGHpVavXu3487p16xQUFOR4bbPZtGHDBkVERLi0OAAAAGcVO9z07t1bkmSxWBQTE5PvPR8fH0VERGjmzJkuLQ4AAMBZxQ43drtdklS/fn19++23Cg4OdltRAAAAJeX01VJpaWnuqAMAAMAlSnQp+Llz5/TFF1/o0KFDysnJyffesGHDXFIYAABASTgdbnbt2qUePXro/PnzOnfunGrUqKHMzEwFBASoVq1ahBsAAOBRTl8KPmLECPXs2VN//PGH/P399fXXX+vXX39VmzZt9Morr7ijRgAAgGJzOtykpKTomWeekZeXl7y9vZWdna3w8HC99NJLGjt2rDtqBAAAKDanw42Pj4+8vP7crFatWjp06JAkKSgoSL/99ptrqytnDMPQ+ZxLOp9T8CaHAACgdDg95+amm27St99+q+uvv16dO3fWxIkTlZmZqSVLlqhZs2buqLFcMAxDDyRs085f//B0KQAAVGhO99xMnz5dtWvXliS98MILql69up566imdOHFC//nPf1xeYHlxIddWINi0vba6/H28PVQRAAAVk9M9N23btnX8uVatWkpKSnJpQWawY3ykAqze8vfxlsVi8XQ5AABUKE733BQlOTlZd999t9PbzZs3TxEREfLz81P79u21ffv2y65/6tQpDRkyRLVr15avr68aNWqktWvXlrRstwiweivAWolgAwCABzgVbtatW6eRI0dq7NixOnDggCTp559/Vu/evXXzzTc7HtFQXMuXL1dcXJwmTZqk5ORktWzZUlFRUTp+/Hih6+fk5OiOO+7QwYMHtXLlSqWmpmr+/PmqU6eOU58LAADMq9jDUgsWLNDgwYNVo0YN/fHHH3rrrbc0a9YsDR06VNHR0frxxx/VpEkTpz581qxZGjx4sAYNGiRJSkhI0Jo1a7Rw4UKNHj26wPoLFy7UyZMn9dVXX8nHx0eSrvgk8uzsbGVnZzteZ2VlOVUjAAAoX4rdczNnzhy9+OKLyszM1HvvvafMzEy9/vrr+uGHH5SQkOB0sMnJydHOnTsVGRn5v2K8vBQZGalt27YVus3q1avVoUMHDRkyRCEhIWrWrJmmT58um63oS6/j4+MVFBTkWMLDw52qEwAAlC/FDjf79+/Xgw8+KEm67777VKlSJb388suqW7duiT44MzNTNptNISEh+dpDQkKUnp5e6DYHDhzQypUrZbPZtHbtWk2YMEEzZ87UtGnTivycMWPG6PTp046lot+LBwAAsyv2sNSFCxcUEBAgSbJYLPL19XVcEl5a7Ha7atWqpTfffFPe3t5q06aNjhw5opdfflmTJk0qdBtfX1/5+vqWap0AAMBznLoU/K233lKVKlUkSZcuXVJiYqKCg4PzrVPcB2cGBwfL29tbGRkZ+dozMjIUGhpa6Da1a9eWj4+PvL3/d++YJk2aKD09XTk5ObJarc4cDgAAMKFih5t69epp/vz5jtehoaFasmRJvnUsFkuxw43ValWbNm20YcMG9e7dW9KfPTMbNmxQbGxsodt06tRJ77zzjux2u+MREHv37lXt2rUJNgAAQJIT4ebgwYMu//C4uDjFxMSobdu2ateunWbPnq1z5845rp4aMGCA6tSpo/j4eEnSU089pddee03Dhw/X0KFD9csvv2j69OnFDlQAAMD8nL5DsStFR0frxIkTmjhxotLT09WqVSslJSU5JhkfOnTI0UMjSeHh4Vq3bp1GjBihFi1aqE6dOho+fLhGjRrlqUMAAABljMUwDMPTRZSmrKwsBQUF6fTp0woMDHTZfs/nXFLTieskSbunRinA6tHcCACAqTjz/e2yxy8AAACUBYQbAABgKoQbAABgKiUKN/v379f48eP18MMPOx5y+emnn+qnn35yaXEAAADOcjrcfPHFF2revLm++eYbrVq1SmfPnpUkfffdd0XeJRgAAKC0OB1uRo8erWnTpumzzz7Ld+O822+/XV9//bVLiwMAAHCW0+Hmhx9+0L333lugvVatWsrMzHRJUQAAACXldLipVq2ajh07VqB9165dqlOnjkuKAgAAKCmnw81DDz2kUaNGKT09XRaLRXa7XVu3btXIkSM1YMAAd9QIAABQbE6Hm+nTp+uGG25QeHi4zp49q6ZNm+of//iHOnbsqPHjx7ujRgAAgGJz+hkBVqtV8+fP14QJE/Tjjz/q7Nmzuummm3T99de7oz4AAACnOB1utmzZoltuuUX16tVTvXr13FETAABAiTk9LHX77berfv36Gjt2rHbv3u2OmgAAAErM6XBz9OhRPfPMM/riiy/UrFkztWrVSi+//LIOHz7sjvoAAACc4nS4CQ4OVmxsrLZu3ar9+/frwQcf1KJFixQREaHbb7/dHTUCAAAU21U9OLN+/foaPXq0ZsyYoebNm+uLL75wVV0AAAAlUuJws3XrVj399NOqXbu2+vbtq2bNmmnNmjWurA0AAMBpTl8tNWbMGC1btkxHjx7VHXfcoTlz5qhXr14KCAhwR30AAABOcTrcfPnll3r22WfVp08fBQcHu6MmAACAEnM63GzdutUddQAAALhEscLN6tWrdeedd8rHx0erV6++7Lr33HOPSwoDAAAoiWKFm969eys9PV21atVS7969i1zPYrHIZrO5qjYAAACnFSvc2O32Qv8MAABQ1jh9KfjixYuVnZ1doD0nJ0eLFy92SVEAAAAl5XS4GTRokE6fPl2g/cyZMxo0aJBLigIAACgpp8ONYRiyWCwF2g8fPqygoCCXFAUAAFBSxb4U/KabbpLFYpHFYlHXrl1VqdL/NrXZbEpLS1P37t3dUiQAAEBxFTvc5F0llZKSoqioKFWpUsXxntVqVUREhO6//36XFwgAAOCMYoebSZMmSZIiIiIUHR0tPz8/txUFAABQUk7foTgmJsYddQAAALhEscJNjRo1tHfvXgUHB6t69eqFTijOc/LkSZcVBwAA4KxihZtXX31VVatWdfz5cuEGAADAk4oVbv46FDVw4EB31QIAAHDVnL7PTXJysn744QfH648++ki9e/fW2LFjlZOT49LiAAAAnOV0uHniiSe0d+9eSdKBAwcUHR2tgIAArVixQs8995zLCwQAAHCG0+Fm7969atWqlSRpxYoV6ty5s9555x0lJibq/fffd3V9AAAATinR4xfyngy+fv169ejRQ5IUHh6uzMxM11YHAADgJKfDTdu2bTVt2jQtWbJEX3zxhe666y5JUlpamkJCQlxeIAAAgDOcDjezZ89WcnKyYmNjNW7cOF133XWSpJUrV6pjx44uLxAAAMAZTt+huEWLFvmulsrz8ssvy9vb2yVFAQAAlJTT4SbPzp07tWfPHklS06ZN1bp1a5cVBQAAUFJOh5vjx48rOjpaX3zxhapVqyZJOnXqlLp06aJly5apZs2arq4RAACg2JyeczN06FCdPXtWP/30k06ePKmTJ0/qxx9/VFZWloYNG+aOGgEAAIrN6Z6bpKQkrV+/Xk2aNHG0NW3aVPPmzVO3bt1cWhwAAICznO65sdvt8vHxKdDu4+PjuP8NAACApzgdbm6//XYNHz5cR48edbQdOXJEI0aMUNeuXV1aHAAAgLOcDjevvfaasrKyFBERoYYNG6phw4aqX7++srKyNHfuXHfUCAAAUGxOz7kJDw9XcnKyNmzY4LgUvEmTJoqMjHR5cQAAAM5yKtwsX75cq1evVk5Ojrp27aqhQ4e6qy4AAIASKXa4eeONNzRkyBBdf/318vf316pVq7R//369/PLL7qwPAADAKcWec/Paa69p0qRJSk1NVUpKihYtWqTXX3/dnbUBAAA4rdjh5sCBA4qJiXG87tu3ry5duqRjx465pTAAAICSKHa4yc7OVuXKlf+3oZeXrFarLly44JbCAAAASsKpCcUTJkxQQECA43VOTo5eeOEFBQUFOdpmzZrluuoAAACcVOxw849//EOpqan52jp27KgDBw44XlssFtdVBgAAUALFDjebNm1yYxkAAACu4fQdit1h3rx5ioiIkJ+fn9q3b6/t27cXa7tly5bJYrGod+/e7i0QAACUGx4PN8uXL1dcXJwmTZqk5ORktWzZUlFRUTp+/Phltzt48KBGjhypW2+9tZQqBQAA5YHHw82sWbM0ePBgDRo0SE2bNlVCQoICAgK0cOHCIrex2Wzq16+fpkyZogYNGpRitQAAoKzzaLjJycnRzp078z2XysvLS5GRkdq2bVuR202dOlW1atXSo48+esXPyM7OVlZWVr4FAACYl0fDTWZmpmw2m0JCQvK1h4SEKD09vdBttmzZogULFmj+/PnF+oz4+HgFBQU5lvDw8KuuGwAAlF0lCjebN2/WP//5T3Xo0EFHjhyRJC1ZskRbtmxxaXF/d+bMGfXv31/z589XcHBwsbYZM2aMTp8+7Vh+++03t9YIAAA8y6mb+EnS+++/r/79+6tfv37atWuXsrOzJUmnT5/W9OnTtXbt2mLvKzg4WN7e3srIyMjXnpGRodDQ0ALr79+/XwcPHlTPnj0dbXa7/c8DqVRJqampatiwYb5tfH195evrW+yaAABA+eZ0z820adOUkJCg+fPny8fHx9HeqVMnJScnO7Uvq9WqNm3aaMOGDY42u92uDRs2qEOHDgXWv+GGG/TDDz8oJSXFsdxzzz3q0qWLUlJSGHICAADO99ykpqbqH//4R4H2oKAgnTp1yukC4uLiFBMTo7Zt26pdu3aaPXu2zp07p0GDBkmSBgwYoDp16ig+Pl5+fn5q1qxZvu2rVasmSQXaAQBAxeR0uAkNDdW+ffsUERGRr33Lli0luiw7OjpaJ06c0MSJE5Wenq5WrVopKSnJMcn40KFD8vLy+BXrAACgnHA63AwePFjDhw/XwoULZbFYdPToUW3btk0jR47UhAkTSlREbGysYmNjC33vSo99SExMLNFnAgAAc3I63IwePVp2u11du3bV+fPn9Y9//EO+vr4aOXKkhg4d6o4aAQAAis3pcGOxWDRu3Dg9++yz2rdvn86ePaumTZuqSpUq7qgPAADAKU6HmzxWq1VNmzZ1ZS0AAABXzelw06VLF1ksliLf37hx41UVBAAAcDWcDjetWrXK9zo3N1cpKSn68ccfFRMT46q6AAAASsTpcPPqq68W2j558mSdPXv2qgsCAAC4Gi67gcw///lPLVy40FW7AwAAKBGXhZtt27bJz8/PVbsDAAAoEaeHpe677758rw3D0LFjx7Rjx44S38QPAADAVZwON0FBQflee3l5qXHjxpo6daq6devmssIAAABKwqlwY7PZNGjQIDVv3lzVq1d3V00AAAAl5tScG29vb3Xr1q1ET/8GAAAoDU5PKG7WrJkOHDjgjloAAACumtPhZtq0aRo5cqQ++eQTHTt2TFlZWfkWAAAATyr2nJupU6fqmWeeUY8ePSRJ99xzT77HMBiGIYvFIpvN5voqAQAAiqnY4WbKlCl68skn9fnnn7uzHgAAgKtS7HBjGIYkqXPnzm4rBgAA4Go5Nefmck8DBwAAKAucus9No0aNrhhwTp48eVUFAQAAXA2nws2UKVMK3KEYAACgLHEq3Dz00EOqVauWu2oBAAC4asWec8N8GwAAUB4UO9zkXS0FAABQlhV7WMput7uzDgAAAJdw+vELAAAAZRnhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmEqZCDfz5s1TRESE/Pz81L59e23fvr3IdefPn69bb71V1atXV/Xq1RUZGXnZ9QEAQMXi8XCzfPlyxcXFadKkSUpOTlbLli0VFRWl48ePF7r+pk2b9PDDD+vzzz/Xtm3bFB4erm7duunIkSOlXDkAACiLLIZhGJ4soH379rr55pv12muvSZLsdrvCw8M1dOhQjR49+orb22w2Va9eXa+99poGDBhwxfWzsrIUFBSk06dPKzAw8Krrz3M+55KaTlwnSdo9NUoB1kou2zcAABWdM9/fHu25ycnJ0c6dOxUZGelo8/LyUmRkpLZt21asfZw/f165ubmqUaNGoe9nZ2crKysr3wIAAMzLo+EmMzNTNptNISEh+dpDQkKUnp5erH2MGjVKYWFh+QLSX8XHxysoKMixhIeHX3XdAACg7PL4nJurMWPGDC1btkwffPCB/Pz8Cl1nzJgxOn36tGP57bffSrlKAABQmjw6MSQ4OFje3t7KyMjI156RkaHQ0NDLbvvKK69oxowZWr9+vVq0aFHker6+vvL19XVJvQAAoOzzaM+N1WpVmzZttGHDBkeb3W7Xhg0b1KFDhyK3e+mll/T8888rKSlJbdu2LY1SAQBAOeHxS3ri4uIUExOjtm3bql27dpo9e7bOnTunQYMGSZIGDBigOnXqKD4+XpL04osvauLEiXrnnXcUERHhmJtTpUoVValSxWPHAQAAygaPh5vo6GidOHFCEydOVHp6ulq1aqWkpCTHJONDhw7Jy+t/HUxvvPGGcnJy9MADD+Tbz6RJkzR58uTSLB0AAJRBHr/PTWnjPjcAAJQ/5eY+NwAAAK5GuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZSydMFAAAuz2azKTc319NlAG7n4+Mjb2/vq94P4QYAyrCzZ8/q8OHDMgzD06UAbmexWFS3bl1VqVLlqvZDuAGAMspms+nw4cMKCAhQzZo1ZbFYPF0S4DaGYejEiRM6fPiwrr/++qvqwSHcAEAZlZubK8MwVLNmTfn7+3u6HMDtatasqYMHDyo3N/eqwg0TigGgjKPHBhWFq37WCTcAAMBUCDcAAMBUCDcAAMBUCDcAABSif//+mj59uqfLMI2kpCS1atVKdrvd7Z9FuAEAlBnvv/++brvtNgUFBalKlSpq0aKFpk6dqpMnT0qSEhMTZbFY1L1793zbnTp1ShaLRZs2bXK0WSwW+fn56ddff823bu/evTVw4MDL1vHdd99p7dq1GjZsWIH33n33XXl7e2vIkCEF3ktMTFS1atUK3afFYtGHH37o1PG6w8mTJ9WvXz8FBgaqWrVqevTRR3X27NnLbrN//37de++9qlmzpgIDA9WnTx9lZGQ43t+0aZMsFkuhy7fffitJ6t69u3x8fLR06VK3HVsewg0AlBOGYeh8ziWPLKVxE8Fx48YpOjpaN998sz799FP9+OOPmjlzpr777jstWbLEsV6lSpW0fv16ff7551fcp8Vi0cSJE52uZe7cuXrwwQcLvZncggUL9Nxzz+ndd9/VxYsXnd53nuIer6v169dPP/30kz777DN98skn+vLLL/X4448Xuf65c+fUrVs3WSwWbdy4UVu3blVOTo569uzp6IXp2LGjjh07lm957LHHVL9+fbVt29axr4EDB+rf//63244tD/e5AYBy4kKuTU0nrvPIZ++eGqUAa/G+Mm677TY1b95c3t7eWrRokaxWq6ZNm6a+ffsqNjZWK1euVEhIiObOnas777xTkrR9+3ZNnz5ds2fP1vDhwx37ioiI0B133KFTp0452ipXrqw+ffpo9OjR+uabby5bS2xsrGbNmqVnn31WzZo1K1b9NptNK1euLLSHIS0tTV999ZXef/99ff7551q1apX69u1brP3+lTPH60p79uxRUlKSvv32W0fomDt3rnr06KFXXnlFYWFhBbbZunWrDh48qF27dikwMFCStGjRIlWvXl0bN25UZGSkrFarQkNDHdvk5ubqo48+0tChQ/Nd3t2zZ0/FxsZq//79atiwoVuOUSojPTfz5s1TRESE/Pz81L59e23fvv2y669YsUI33HCD/Pz81Lx5c61du7aUKgUAFMeiRYsUHBys7du3a+jQoXrqqaf04IMPqmPHjkpOTla3bt3Uv39/nT9/XpK0dOlSValSRU8//XSh+/v7UM/kyZP1ww8/aOXKlZeto1OnTrr77rs1evToYtf+/fff6/Tp0/l6HPK8/fbbuuuuuxQUFKR//vOfWrBgQbH3+1fOHu9f3XjjjapSpUqRS15gLMy2bdtUrVq1fMcWGRkpLy+vIoNidna2LBaLfH19HW1+fn7y8vLSli1bCt1m9erV+v333zVo0KB87fXq1VNISIg2b95cZI2u4PGem+XLlysuLk4JCQlq3769Zs+eraioKKWmpqpWrVoF1v/qq6/08MMPKz4+Xnfffbfeeecd9e7dW8nJycVO5QBQHvn7eGv31CiPfbYzWrZsqfHjx0uSxowZoxkzZig4OFiDBw+WJE2cOFFvvPGGvv/+e/3f//2ffvnlFzVo0EA+Pj7F2n9YWJiGDx+ucePGqXfv3pddNz4+Xi1atNDmzZt16623XnHfv/76q7y9vQt8B9ntdiUmJmru3LmSpIceekjPPPOM0tLSVL9+/WLVncfZ4/2rtWvXXvZBqpe7m3V6enqB46pUqZJq1Kih9PT0Qrf5v//7P1WuXFmjRo3S9OnTZRiGRo8eLZvNpmPHjhW6zYIFCxQVFaW6desWeC8sLKzAPChX83jPzaxZszR48GANGjRITZs2VUJCggICArRw4cJC158zZ466d++uZ599Vk2aNNHzzz+v1q1b67XXXivlygGgdFksFgVYK3lkcfbOsS1atHD82dvbW9dcc42aN2/uaAsJCZEkHT9+XJJKNKdn1KhROnHiRJHfF3maNm2qAQMGFLv35sKFC/L19S1wzJ999pnOnTunHj16SJKCg4N1xx13XPHzC3M1c5iuvfZaXXfddUUuderUKfG+C1OzZk2tWLFCH3/8sapUqaKgoCCdOnVKrVu3lpdXwRhx+PBhrVu3To8++mih+/P393f02LmLR8NNTk6Odu7cqcjISEebl5eXIiMjtW3btkK32bZtW771JSkqKqrI9bOzs5WVlZVvAQC41997JCwWS762vOCQNyG1UaNGOnDgwGV7JP6uWrVqGjNmjKZMmXLFL8spU6YoOTm5wNVKhQkODtb58+eVk5OTr33BggU6efKk/P39ValSJVWqVElr167VokWLHMcRGBioc+fOFbjcOW8OTVBQkKSSHW+eqxmWCg0NdQTKPJcuXdLJkyfzzZn5u27dumn//v06fvy4MjMztWTJEh05ckQNGjQosO7bb7+ta665Rvfcc0+h+zp58qRq1qxZzKMtGY+Gm8zMTNlsNkeCzxMSElJk91h6erpT68fHxysoKMixhIeHu6Z4AIDL9O3bV2fPntXrr79e6PtFTbAdOnSovLy8NGfOnMvuPzw8XLGxsRo7dqxsNttl123VqpUkaffu3Y6233//XR999JGWLVumlJQUx7Jr1y798ccf+u9//ytJaty4sS5duqSUlJR8+0xOTpb0Z6i5muOV/hyW+msNf1/eeuutIrft0KGDTp06pZ07dzraNm7cKLvdrvbt2xe5XZ7g4GBVq1ZNGzdu1PHjxwsEGMMw9Pbbb2vAgAGFDrldvHhR+/fv10033XTFz7oaHp9z425jxoxRXFyc43VWVpZbAs5fx8KdHZsGgIquffv2eu655/TMM8/oyJEjuvfeexUWFqZ9+/YpISFBt9xyS76rivL4+flpypQphd5z5u/GjBmj+fPnKy0tTdHR0UWuV7NmTbVu3VpbtmxxBJ0lS5bommuuUZ8+fQoMV/Xo0UMLFixQ9+7ddeONN6pbt2565JFHNHPmTDVo0ECpqan617/+pejoaMeQUUmPV/pzWKqkmjRpou7du2vw4MFKSEhQbm6uYmNj9dBDDzmulDpy5Ii6du2qxYsXq127dpL+7I1p0qSJatasqW3btmn48OEaMWKEGjdunG//GzduVFpamh577LFCP//rr7+Wr6+vOnToUOJjKA6P9twEBwfL29s7342AJCkjI6PI7rHQ0FCn1vf19VVgYGC+xR3+OhbOE3wBwHkvvvii3nnnHX3zzTeKiorSjTfeqLi4OLVo0UIxMTFFbhcTE1Po8Mjf1ahRQ6NGjSrWvWkee+yxfJeCL1y4UPfee2+h/7/ff//9Wr16tTIzMyX9eaFM586d9cQTT+jGG2/UsGHD1KtXrwI9KiU93qu1dOlS3XDDDeratat69OihW265RW+++abj/dzcXKWmpuYb6ktNTVXv3r3VpEkTTZ06VePGjdMrr7xSYN8LFixQx44ddcMNNxT62e+++6769eungIAA1x/YX1iM0rgz02W0b99e7dq1c8w+t9vtqlevnmJjYwud/BUdHa3z58/r448/drR17NhRLVq0UEJCwhU/LysrS0FBQTp9+rTbgg4AuMLFixcdV+L4+fl5upwK5cKFC2rcuLGWL1/u9l6GiiIzM1ONGzfWjh07iry67HI/8858f3t8WCouLk4xMTFq27at2rVrp9mzZ+vcuXOOa+MHDBigOnXqKD4+XpI0fPhwde7cWTNnztRdd92lZcuWaceOHflSJwAAV8Pf31+LFy929Mbg6h08eFCvv/6605fNl4THw010dLROnDihiRMnKj09Xa1atVJSUpJj0vChQ4fyXWrWsWNHvfPOOxo/frzGjh2r66+/Xh9++CH3uAEAuNRtt93m6RJMpW3btoXeGNEdPD4sVdoYlgJQXjAshYrGVcNSHr+JHwDg8irY76CowFz1s064AYAyytv7z9tK/P1mcoBZ5f2s5/3sl5TH59wAAApXqVIlBQQE6MSJE/Lx8Sn0VveAWdjtdp04cUIBAQGqVOnq4gnhBgDKKIvFotq1aystLc3tDxoEygIvLy/Vq1fvqu8XR7gBgDLMarXq+uuvZ2gKFYLVanVJDyXhBgDKOC8vL66WApzAAC4AADAVwg0AADAVwg0AADCVCjfnJu8GQVlZWR6uBAAAFFfe93ZxbvRX4cLNmTNnJEnh4eEergQAADjrzJkzCgoKuuw6Fe7ZUna7XUePHlXVqlWv+jr6v8vKylJ4eLh+++03nlvlRpzn0sF5Lh2c59LDuS4d7jrPhmHozJkzCgsLu+Ll4hWu58bLy0t169Z162cEBgbyD6cUcJ5LB+e5dHCeSw/nunS44zxfqccmDxOKAQCAqRBuAACAqRBuXMjX11eTJk2Sr6+vp0sxNc5z6eA8lw7Oc+nhXJeOsnCeK9yEYgAAYG703AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3Dhp3rx5ioiIkJ+fn9q3b6/t27dfdv0VK1bohhtukJ+fn5o3b661a9eWUqXlmzPnef78+br11ltVvXp1Va9eXZGRkVf8e8GfnP15zrNs2TJZLBb17t3bvQWahLPn+dSpUxoyZIhq164tX19fNWrUiP87isHZ8zx79mw1btxY/v7+Cg8P14gRI3Tx4sVSqrZ8+vLLL9WzZ0+FhYXJYrHoww8/vOI2mzZtUuvWreXr66vrrrtOiYmJbq9TBopt2bJlhtVqNRYuXGj89NNPxuDBg41q1aoZGRkZha6/detWw9vb23jppZeM3bt3G+PHjzd8fHyMH374oZQrL1+cPc99+/Y15s2bZ+zatcvYs2ePMXDgQCMoKMg4fPhwKVdevjh7nvOkpaUZderUMW699VajV69epVNsOebsec7Ozjbatm1r9OjRw9iyZYuRlpZmbNq0yUhJSSnlyssXZ8/z0qVLDV9fX2Pp0qVGWlqasW7dOqN27drGiBEjSrny8mXt2rXGuHHjjFWrVhmSjA8++OCy6x84cMAICAgw4uLijN27dxtz5841vL29jaSkJLfWSbhxQrt27YwhQ4Y4XttsNiMsLMyIj48vdP0+ffoYd911V7629u3bG0888YRb6yzvnD3Pf3fp0iWjatWqxqJFi9xVoimU5DxfunTJ6Nixo/HWW28ZMTExhJticPY8v/HGG0aDBg2MnJyc0irRFJw9z0OGDDFuv/32fG1xcXFGp06d3FqnmRQn3Dz33HPGjTfemK8tOjraiIqKcmNlhsGwVDHl5ORo586dioyMdLR5eXkpMjJS27ZtK3Sbbdu25VtfkqKioopcHyU7z393/vx55ebmqkaNGu4qs9wr6XmeOnWqatWqpUcffbQ0yiz3SnKeV69erQ4dOmjIkCEKCQlRs2bNNH36dNlsttIqu9wpyXnu2LGjdu7c6Ri6OnDggNauXasePXqUSs0Vhae+ByvcgzNLKjMzUzabTSEhIfnaQ0JC9PPPPxe6TXp6eqHrp6enu63O8q4k5/nvRo0apbCwsAL/oPA/JTnPW7Zs0YIFC5SSklIKFZpDSc7zgQMHtHHjRvXr109r167Vvn379PTTTys3N1eTJk0qjbLLnZKc5759+yozM1O33HKLDMPQpUuX9OSTT2rs2LGlUXKFUdT3YFZWli5cuCB/f3+3fC49NzCVGTNmaNmyZfrggw/k5+fn6XJM48yZM+rfv7/mz5+v4OBgT5djana7XbVq1dKbb76pNm3aKDo6WuPGjVNCQoKnSzOVTZs2afr06Xr99deVnJysVatWac2aNXr++ec9XRpcgJ6bYgoODpa3t7cyMjLytWdkZCg0NLTQbUJDQ51aHyU7z3leeeUVzZgxQ+vXr1eLFi3cWWa55+x53r9/vw4ePKiePXs62ux2uySpUqVKSk1NVcOGDd1bdDlUkp/n2rVry8fHR97e3o62Jk2aKD09XTk5ObJarW6tuTwqyXmeMGGC+vfvr8cee0yS1Lx5c507d06PP/64xo0bJy8vfvd3haK+BwMDA93WayPRc1NsVqtVbdq00YYNGxxtdrtdGzZsUIcOHQrdpkOHDvnWl6TPPvusyPVRsvMsSS+99JKef/55JSUlqW3btqVRarnm7Hm+4YYb9MMPPyglJcWx3HPPPerSpYtSUlIUHh5emuWXGyX5ee7UqZP27dvnCI+StHfvXtWuXZtgU4SSnOfz588XCDB5gdLgkYsu47HvQbdOVzaZZcuWGb6+vkZiYqKxe/du4/HHHzeqVatmpKenG4ZhGP379zdGjx7tWH/r1q1GpUqVjFdeecXYs2ePMWnSJC4FLwZnz/OMGTMMq9VqrFy50jh27JhjOXPmjKcOoVxw9jz/HVdLFY+z5/nQoUNG1apVjdjYWCM1NdX45JNPjFq1ahnTpk3z1CGUC86e50mTJhlVq1Y13n33XePAgQPGf//7X6Nhw4ZGnz59PHUI5cKZM2eMXbt2Gbt27TIkGbNmzTJ27dpl/Prrr4ZhGMbo0aON/v37O9bPuxT82WefNfbs2WPMmzePS8HLorlz5xr16tUzrFar0a5dO+Prr792vNe5c2cjJiYm3/rvvfee0ahRI8NqtRo33nijsWbNmlKuuHxy5jxfe+21hqQCy6RJk0q/8HLG2Z/nvyLcFJ+z5/mrr74y2rdvb/j6+hoNGjQwXnjhBePSpUulXHX548x5zs3NNSZPnmw0bNjQ8PPzM8LDw42nn37a+OOPP0q/8HLk888/L/T/27xzGxMTY3Tu3LnANq1atTKsVqvRoEED4+2333Z7nRbDoP8NAACYB3NuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAOSTmJioatWqebqMErNYLPrwww8vu87AgQPVu3fvUqkHQOkj3AAmNHDgQFkslgLLvn37PF2aEhMTHfV4eXmpbt26GjRokI4fP+6S/R87dkx33nmnJOngwYOyWCxKSUnJt86cOXOUmJjoks8ryuTJkx3H6e3trfDwcD3++OM6efKkU/shiAHOq+TpAgC4R/fu3fX222/na6tZs6aHqskvMDBQqampstvt+u677zRo0CAdPXpU69atu+p9h4aGXnGdoKCgq/6c4rjxxhu1fv162Ww27dmzR4888ohOnz6t5cuXl8rnAxUVPTeASfn6+io0NDTf4u3trVmzZql58+aqXLmywsPD9fTTT+vs2bNF7ue7775Tly5dVLVqVQUGBqpNmzbasWOH4/0tW7bo1ltvlb+/v8LDwzVs2DCdO3fusrVZLBaFhoYqLCxMd955p4YNG6b169frwoULstvtmjp1qurWrStfX1+1atVKSUlJjm1zcnIUGxur2rVry8/PT9dee63i4+Pz7TtvWKp+/fqSpJtuukkWi0W33XabpPy9IW+++abCwsJkt9vz1dirVy898sgjjtcfffSRWrduLT8/PzVo0EBTpkzRpUuXLnuclSpVUmhoqOrUqaPIyEg9+OCD+uyzzxzv22w2Pfroo6pfv778/f3VuHFjzZkzx/H+5MmTtWjRIn300UeOXqBNmzZJkn777Tf16dNH1apVU40aNdSrVy8dPHjwsvUAFQXhBqhgvLy89O9//1s//fSTFi1apI0bN+q5554rcv1+/fqpbt26+vbbb7Vz506NHj1aPj4+kqT9+/ere/fuuv/++/X9999r+fLl2rJli2JjY52qyd/fX3a7XZcuXdKcOXM0c+ZMvfLKK/r+++8VFRWle+65R7/88osk6d///rdWr16t9957T6mpqVq6dKkiIiIK3e/27dslSevXr9exY8e0atWqAus8+OCD+v333/X555872k6ePKmkpCT169dPkrR582YNGDBAw4cP1+7du/Wf//xHiYmJeuGFF4p9jAcPHtS6detktVodbXa7XXXr1tWKFSu0e/duTZw4UWPHjtV7770nSRo5cqT69Omj7t2769ixYzp27Jg6duyo3NxcRUVFqWrVqtq8ebO2bt2qKlWqqHv37srJySl2TYBpuf254wBKXUxMjOHt7W1UrlzZsTzwwAOFrrtixQrjmmuucbx+++23jaCgIMfrqlWrGomJiYVu++ijjxqPP/54vrbNmzcbXl5exoULFwrd5u/737t3r9GoUSOjbdu2hmEYRlhYmPHCCy/k2+bmm282nn76acMwDGPo0KHG7bffbtjt9kL3L8n44IMPDMMwjLS0NEOSsWvXrnzrxMTEGL169XK87tWrl/HII484Xv/nP/8xwsLCDJvNZhiGYXTt2tWYPn16vn0sWbLEqF27dqE1GIZhTJo0yfDy8jIqV65s+Pn5GZIMScasWbOK3MYwDGPIkCHG/fffX2SteZ/duHHjfOcgOzvb8Pf3N9atW3fZ/QMVAXNuAJPq0qWL3njjDcfrypUrS/qzFyM+Pl4///yzsrKydOnSJV28eFHnz59XQEBAgf3ExcXpscce05IlSxxDKw0bNpT055DV999/r6VLlzrWNwxDdrtdaWlpatKkSaG1nT59WlWqVJHdbtfFixd1yy236K233lJWVpaOHj2qTp065Vu/U6dO+u677yT9OaR0xx13qHHjxurevbvuvvtudevW7arOVb9+/TR48GC9/vrr8vX11dKlS/XQQw/Jy8vLcZxbt27N11Njs9kue94kqXHjxlq9erUuXryo//f//p9SUlI0dOjQfOvMmzdPCxcu1KFDh3ThwgXl5OSoVatWl633u+++0759+1S1atV87RcvXtT+/ftLcAYAcyHcACZVuXJlXXfddfnaDh48qLvvvltPPfWUXnjhBdWoUUNbtmzRo48+qpycnEK/pCdPnqy+fftqzZo1+vTTTzVp0iQtW7ZM9957r86ePasnnnhCw4YNK7BdvXr1iqytatWqSk5OlpeXl2rXri1/f39JUlZW1hWPq3Xr1kpLS9Onn36q9evXq0+fPoqMjNTKlSuvuG1RevbsKcMwtGbNGt18883avHmzXn31Vcf7Z8+e1ZQpU3TfffcV2NbPz6/I/VqtVsffwYwZM3TXXXdpypQpev755yVJy5Yt08iRIzVz5kx16NBBVatW1csvv6xvvvnmsvWePXtWbdq0yRcq85SVSeOAJxFugApk586dstvtmjlzpqNXIm9+x+U0atRIjRo10ogRI/Twww/r7bff1r333qvWrVtr9+7dBULUlXh5eRW6TWBgoMLCwrR161Z17tzZ0b5161a1a9cu33rR0dGKjo7WAw88oO7du+vkyZOqUaNGvv3lzW+x2WyXrcfPz0/33Xefli5dqn379qlx48Zq3bq14/3WrVsrNTXV6eP8u/Hjx+v222/XU0895TjOjh076umnn3as8/eeF6vVWqD+1q1ba/ny5apVq5YCAwOvqibAjJhQDFQg1113nXJzczV37lwdOHBAS5YsUUJCQpHrX7hwQbGxsdq0aZN+/fVXbd26Vd9++61juGnUqFH66quvFBsbq5SUFP3yyy/66KOPnJ5Q/FfPPvusXnzxRS1fvlypqakaPXq0UlJSNHz4cEnSrFmz9O677+rnn3/W3r17tWLFCoWGhhZ648FatWrJ399fSUlJysjI0OnTp4v83H79+mnNmjVauHChYyJxnokTJ2rx4sWaMmWKfvrpJ+3Zs0fLli3T+PHjnTq2Dh06qEWLFpo+fbok6frrr9eOHTu0bt067d27VxMmTNC3336bb5uIiAh9//33Sk1NVWZmpnJzc9WvXz8FBwerV69e2rx5s9LS0rRp0yYNGzZMhw8fdqomwJQ8PekHgOsVNgk1z6xZs4zatWsb/v7+RlRUlLF48WJDkvHHH38YhpF/wm92drbx0EMPGeHh4YbVajXCwsKM2NjYfJOFt2/fbtxxxx1GlSpVjMqVKxstWrQoMCH4r/4+ofjvbDabMXnyZKNOnTqGj4+P0bJlS+PTTz91vP/mm28arVq1MipXrmwEBgYaXbt2NZKTkx3v6y8Tig3DMObPn2+Eh4cbXl5eRufOnYs8Pzabzahdu7Yhydi/f3+BupKSkoyOHTsa/v7+RmBgoNGuXTvjzTffLPI4Jk2aZLRs2bJA+7vvvmv4+voahw4dMi5evGgMHDjQCAoKMqpVq2Y89dRTxujRo/Ntd/z4ccf5lWR8/vnnhmEYxrFjx4wBAwYYwcHBhq+vr9GgQQNj8ODBxunTp4usCagoLIZhGJ6NVwAAAK7DsBQAADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADCV/w9ZbLwEbqN43wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, RocCurveDisplay\n",
        "import numpy as np\n",
        "import math\n",
        "import gc\n",
        "from sklearn.model_selection import KFold\n",
        "import csv\n",
        "\n",
        "# Define constants (Set these according to your data and needs)\n",
        "MAXSEQ = 1274\n",
        "NUM_FEATURE = 20\n",
        "NUM_CLASSES = 2\n",
        "WINDOW_SIZES = [32]  # Example\n",
        "NUM_FILTER = 256\n",
        "NUM_HIDDEN = 512\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "K_Fold = 5\n",
        "VALIDATION_MODE = \"cross\"\n",
        "\n",
        "# Define load_ds function\n",
        "def load_ds(file_path):\n",
        "    NUM_SAMPLES = 0\n",
        "    with open(file_path) as file:\n",
        "        NUM_SAMPLES = sum(1 for row in file)\n",
        "\n",
        "    data = np.zeros((NUM_SAMPLES, MAXSEQ * NUM_FEATURE), dtype=np.float32)\n",
        "    labels = np.zeros((NUM_SAMPLES, 1), dtype=np.uint8)\n",
        "\n",
        "    with open(file_path) as file:\n",
        "        file = csv.reader(file, delimiter=',')\n",
        "        m = 0\n",
        "        for row in file:\n",
        "            labels[m] = int(row[0])\n",
        "            data[m] = np.array(row[1:]).astype('float32')\n",
        "            m += 1\n",
        "            print(f\"\\rReading {file_path}...\\t{m}/{NUM_SAMPLES}\", end='')\n",
        "    print('\\tDone')\n",
        "    return data, labels\n",
        "\n",
        "# Load training and testing data\n",
        "x_train, y_train = load_ds('/content/drive/MyDrive/s1116049/train_data_A.csv')\n",
        "x_test, y_test = load_ds('/content/drive/MyDrive/s1116049/test_data_A.csv')\n",
        "\n",
        "# Reshape data to add channels dimension\n",
        "x_train = np.reshape(x_train, [-1, 1, MAXSEQ, NUM_FEATURE])\n",
        "x_test = np.reshape(x_test, [-1, 1, MAXSEQ, NUM_FEATURE])\n",
        "\n",
        "# Define DeepScan class\n",
        "class DeepScan(Model):\n",
        "    def __init__(self, input_shape=(1, MAXSEQ, NUM_FEATURE), window_sizes=[32], num_filters=256, num_hidden=512):\n",
        "        super(DeepScan, self).__init__()\n",
        "\n",
        "        self.window_sizes = window_sizes\n",
        "        self.conv_layers = []\n",
        "        self.pool_layers = []\n",
        "        self.flatten_layers = []\n",
        "\n",
        "        for window_size in self.window_sizes:\n",
        "            self.conv_layers.append(\n",
        "                layers.Conv2D(filters=num_filters,\n",
        "                              kernel_size=(1, window_size),\n",
        "                              activation='relu',\n",
        "                              padding='valid')\n",
        "            )\n",
        "            self.pool_layers.append(\n",
        "                layers.MaxPooling2D(pool_size=(1, MAXSEQ - window_size + 1),\n",
        "                                    strides=(1, MAXSEQ - window_size + 1),\n",
        "                                    padding='valid')\n",
        "            )\n",
        "            self.flatten_layers.append(layers.Flatten())\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=0.5)\n",
        "        self.fc1 = layers.Dense(num_hidden, activation='relu')\n",
        "        self.fc2 = layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(1e-3))\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x_list = []\n",
        "        for i in range(len(self.window_sizes)):\n",
        "            x_conv = self.conv_layers[i](x)\n",
        "            x_pool = self.pool_layers[i](x_conv)\n",
        "            x_flat = self.flatten_layers[i](x_pool)\n",
        "            x_list.append(x_flat)\n",
        "\n",
        "        x = tf.concat(x_list, axis=1)\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Build the model to initialize layers\n",
        "        super(DeepScan, self).build(input_shape)\n",
        "\n",
        "# Define model_test function\n",
        "def model_test(model, x_test, y_test):\n",
        "    # Generate predictions\n",
        "    pred_test = model.predict(x_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    fpr, tpr, thresholds = roc_curve(y_test[:, 0], pred_test[:, 1])\n",
        "    AUC = auc(fpr, tpr)\n",
        "    display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=AUC, estimator_name='DeepScan')\n",
        "    display.plot()\n",
        "\n",
        "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
        "    ix = np.argmax(gmeans)\n",
        "    print(f'\\nBest Threshold={thresholds[ix]}, G-Mean={gmeans[ix]}')\n",
        "    threshold = thresholds[ix]\n",
        "    y_pred = (pred_test[:, 1] >= threshold).astype(int)\n",
        "\n",
        "    TN, FP, FN, TP = confusion_matrix(y_test[:, 0], y_pred).ravel()\n",
        "    Sens = TP / (TP + FN) if TP + FN > 0 else 0.0\n",
        "    Spec = TN / (FP + TN) if FP + TN > 0 else 0.0\n",
        "    Acc = (TP + TN) / (TP + FP + TN + FN)\n",
        "    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) if TP + FP > 0 and FP + TN > 0 and TP + FN > 0 and TN + FN > 0 else 0.0\n",
        "    F1 = 2 * TP / (2 * TP + FP + FN)\n",
        "    Prec = TP / (TP + FP)\n",
        "    Recall = TP / (TP + FN)\n",
        "\n",
        "    print(f'TP={TP}, FP={FP}, TN={TN}, FN={FN}, Sens={Sens:.4f}, Spec={Spec:.4f}, Acc={Acc:.4f}, MCC={MCC:.4f}, AUC={AUC:.4f}, F1={F1:.4f}, Prec={Prec:.4f}, Recall={Recall:.4f}\\n')\n",
        "\n",
        "    return TP, FP, TN, FN, Sens, Spec, Acc, MCC, AUC, F1, Prec, Recall\n",
        "\n",
        "# Cross-validation code\n",
        "if VALIDATION_MODE == \"cross\":\n",
        "    # Initialize K-Fold cross-validation\n",
        "    kfold = KFold(n_splits=K_Fold, shuffle=True, random_state=2)\n",
        "\n",
        "    results = []  # List to store results of each fold\n",
        "    i = 1  # Counter for fold number\n",
        "\n",
        "    # Iterate over each split of the dataset\n",
        "    for train_index, test_index in kfold.split(x_train):\n",
        "        print(f\"{i} / {K_Fold}\\n\")\n",
        "\n",
        "        # Split the data into training and testing sets for the current fold\n",
        "        X_train, X_test = x_train[train_index], x_train[test_index]\n",
        "        Y_train, Y_test = y_train[train_index], y_train[test_index]\n",
        "\n",
        "        # Print the shapes of the training and testing datasets\n",
        "        print(\"The shape of training dataset of cross validation:\", X_train.shape)\n",
        "        print(\"The shape of training label of cross validation:\", Y_train.shape)\n",
        "        print(\"The shape of validation dataset of cross validation:\", X_test.shape)\n",
        "        print(\"The shape of validation label of cross validation:\", Y_test.shape)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # Initialize the DeepScan model\n",
        "        model = DeepScan(\n",
        "            input_shape=(1, MAXSEQ, NUM_FEATURE),\n",
        "            window_sizes=WINDOW_SIZES,\n",
        "            num_filters=NUM_FILTER,\n",
        "            num_hidden=NUM_HIDDEN\n",
        "        )\n",
        "\n",
        "        # Build the model with the input shape\n",
        "        model.build(input_shape=(None, 1, MAXSEQ, NUM_FEATURE))\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Print the model summary\n",
        "        model.summary()\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(\n",
        "            X_train, Y_train,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            validation_data=(X_test, Y_test),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)],\n",
        "            verbose=1,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        # Test the model on the validation set and get performance metrics\n",
        "        TP, FP, TN, FN, Sens, Spec, Acc, MCC, AUC, F1, Prec, Recall = model_test(model, X_test, Y_test)\n",
        "\n",
        "        # Append the results to the list\n",
        "        results.append([TP, FP, TN, FN, Sens, Spec, Acc, MCC, AUC, F1, Prec, Recall])\n",
        "\n",
        "        # Increment the fold counter\n",
        "        i += 1\n",
        "\n",
        "        # Clear the training and testing data from memory\n",
        "        del X_train\n",
        "        del X_test\n",
        "        del Y_train\n",
        "        del Y_test\n",
        "        gc.collect()\n",
        "\n",
        "    # Calculate the mean results across all folds\n",
        "    mean_results = np.mean(results, axis=0)\n",
        "\n",
        "    # Print the mean results of the cross-validation\n",
        "    print(f\"The mean of {K_Fold}-Fold cross-validation results:\")\n",
        "    print(f'TP={mean_results[0]:.4f}, FP={mean_results[1]:.4f}, TN={mean_results[2]:.4f}, FN={mean_results[3]:.4f}, '\n",
        "          f'Sens={mean_results[4]:.4f}, Spec={mean_results[5]:.4f}, Acc={mean_results[6]:.4f}, MCC={mean_results[7]:.4f}, AUC={mean_results[8]:.4f}, F1={mean_results[9]:.4f}, Prec={mean_results[10]:.4f}, Recall={mean_results[11]:.4f}')\n",
        "else:\n",
        "    # Initialize the DeepScan model\n",
        "    model = DeepScan(\n",
        "        input_shape=(1, MAXSEQ, NUM_FEATURE),\n",
        "        window_sizes=WINDOW_SIZES,\n",
        "        num_filters=NUM_FILTER,\n",
        "        num_hidden=NUM_HIDDEN\n",
        "    )\n",
        "\n",
        "    # Build the model with the input shape\n",
        "    model.build(input_shape=(None, 1, MAXSEQ, NUM_FEATURE))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Print the model summary\n",
        "    model.summary()\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        validation_data=(x_test, y_test),\n",
        "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)],\n",
        "        verbose=1,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # Test the model on the test set and get performance metrics\n",
        "    TP, FP, TN, FN, Sens, Spec, Acc, MCC, AUC, F1, Prec, Recall = model_test(model, x_test, y_test)\n",
        "\n",
        "    # Print the final test results\n",
        "    print(f'TP={TP}, FP={FP}, TN={TN}, FN={FN}, Sens={Sens:.4f}, Spec={Spec:.4f}, Acc={Acc:.4f}, MCC={MCC:.4f}, AUC={AUC:.4f}, F1={F1:.4f}, Prec={Prec:.4f}, Recall={Recall:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "id": "HNGH1HGhqpPE",
        "outputId": "20e93612-1e11-4027-fdd5-ecbf97fb1602"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/drive/MyDrive/s1116049/train_data_A.csv...\t1398/1398\tDone\n",
            "Reading /content/drive/MyDrive/s1116049/test_data_A.csv...\t278/278\tDone\n",
            "1 / 5\n",
            "\n",
            "The shape of training dataset of cross validation: (1118, 1, 1274, 20)\n",
            "The shape of training label of cross validation: (1118, 1)\n",
            "The shape of validation dataset of cross validation: (280, 1, 1274, 20)\n",
            "The shape of validation label of cross validation: (280, 1)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"deep_scan_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"deep_scan_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)                   │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_39 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_39 (\u001b[38;5;33mFlatten\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2edc327ceb68>\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         history = model.fit(\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0;34m\"Arguments `target` and `output` must have the same shape. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0;34m\"Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 2)"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}