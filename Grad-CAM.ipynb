{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a566f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# === Constants ===\n",
    "MAXSEQ = 1274\n",
    "NUM_FEATURE = 20\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "WINDOW_SIZES = [2, 4, 8, 12, 16, 20]\n",
    "\n",
    "# === Load Dataset ===\n",
    "def load_ds(file_path):\n",
    "    with open(file_path) as file:\n",
    "        NUM_SAMPLES = sum(1 for _ in file)\n",
    "    data = np.zeros((NUM_SAMPLES, MAXSEQ * NUM_FEATURE), dtype=np.float32)\n",
    "    labels = np.zeros((NUM_SAMPLES, 1), dtype=np.uint8)\n",
    "    with open(file_path) as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for m, row in enumerate(reader):\n",
    "            labels[m] = int(row[0])\n",
    "            data[m] = np.array(row[1:]).astype('float32')\n",
    "            print(f\"\\rReading {file_path}...\\t{m+1}/{NUM_SAMPLES}\", end='')\n",
    "    print('\\tDone')\n",
    "    return data, labels\n",
    "\n",
    "# === Prepare Data ===\n",
    "x_train, y_train = load_ds('/Hussain/Efflux/train_data_A.csv')\n",
    "x_test, y_test = load_ds('/Hussain/Efflux/test_data_A.csv')\n",
    "x_train = x_train.reshape((-1, MAXSEQ, NUM_FEATURE, 1))\n",
    "x_test = x_test.reshape((-1, MAXSEQ, NUM_FEATURE, 1))\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=NUM_CLASSES)\n",
    "\n",
    "# === Multi-Window CNN Model ===\n",
    "def build_multi_window_cnn():\n",
    "    inputs = layers.Input(shape=(MAXSEQ, NUM_FEATURE, 1))\n",
    "    conv_outputs = []\n",
    "\n",
    "    for w in WINDOW_SIZES:\n",
    "        conv = layers.Conv2D(128, kernel_size=(1, w), activation='relu', padding='valid', name=f\"conv_{w}\")(inputs)\n",
    "        pool = layers.GlobalMaxPooling2D()(conv)\n",
    "        conv_outputs.append(pool)\n",
    "\n",
    "    merged = layers.Concatenate()(conv_outputs)\n",
    "    x = layers.Dense(512, activation='relu')(merged)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "model = build_multi_window_cnn()\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train_cat, batch_size=BATCH_SIZE, epochs=EPOCHS, shuffle=True)\n",
    "\n",
    "# === Evaluation ===\n",
    "pred_test = model.predict(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_cat[:, 1], pred_test[:, 1])\n",
    "AUC = metrics.auc(fpr, tpr)\n",
    "gmeans = np.sqrt(tpr * (1 - fpr))\n",
    "ix = np.argmax(gmeans)\n",
    "threshold = thresholds[ix]\n",
    "y_pred = (pred_test[:, 1] >= threshold).astype(int)\n",
    "\n",
    "TN, FP, FN, TP = metrics.confusion_matrix(y_test_cat[:, 1], y_pred).ravel()\n",
    "Sens = TP / (TP + FN) if TP + FN > 0 else 0.0\n",
    "Spec = TN / (TN + FP) if TN + FP > 0 else 0.0\n",
    "Acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) if TP + FP > 0 and FP + TN > 0 and TP + FN > 0 and TN + FN > 0 else 0.0\n",
    "F1 = 2 * TP / (2 * TP + FP + FN)\n",
    "Prec = TP / (TP + FP) if TP + FP > 0 else 0.0\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "print(f'\\n✅ Final Evaluation Metrics:')\n",
    "print(f'TP={TP}, FP={FP}, TN={TN}, FN={FN}')\n",
    "print(f'Sens={Sens:.4f}, Spec={Spec:.4f}, Acc={Acc:.4f}, MCC={MCC:.4f}')\n",
    "print(f'AUC={AUC:.4f}, F1={F1:.4f}, Prec={Prec:.4f}, Recall={Recall:.4f}')\n",
    "\n",
    "# === Save ROC + AUC ===\n",
    "with open(\"/Hussain/Efflux/auc/A_multi_window_cnn.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"fpr\": fpr,\n",
    "        \"tpr\": tpr,\n",
    "        \"auc\": AUC,\n",
    "        \"y_true\": y_test_cat[:, 1],\n",
    "        \"y_score\": pred_test[:, 1]\n",
    "    }, f)\n",
    "\n",
    "# === Grad-CAM ===\n",
    "def compute_gradcam(model, img_array, class_idx, layer_name=\"conv_2\"):\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
    "    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_tensor)\n",
    "        loss = predictions[:, class_idx]\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(pooled_grads[:, tf.newaxis, tf.newaxis] * conv_outputs, axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-8)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_gradcam(heatmap, original_input, filename, title=\"Grad-CAM\"):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.imshow(original_input.squeeze().T, cmap=\"gray\", aspect=\"auto\")\n",
    "    plt.imshow(heatmap.T, cmap='jet', alpha=0.5, aspect=\"auto\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# === Generate Grad-CAM Heatmaps ===\n",
    "gradcam_output_dir = \"/Hussain/Efflux/A_gradcam_multi_window\"\n",
    "os.makedirs(gradcam_output_dir, exist_ok=True)\n",
    "\n",
    "for idx in range(10):\n",
    "    sample = x_test[idx:idx+1]\n",
    "    true_label = y_test[idx][0]\n",
    "    pred_label = np.argmax(model.predict(sample))\n",
    "    heatmap = compute_gradcam(model, sample, pred_label, layer_name=\"conv_2\")  # use any: conv_2, conv_4, ...\n",
    "\n",
    "    filename = os.path.join(gradcam_output_dir, f\"sample_{idx+1}_true{true_label}_pred{pred_label}.png\")\n",
    "    title = f\"Grad-CAM (Sample {idx+1}) - True: {true_label}, Pred: {pred_label}\"\n",
    "    save_gradcam(heatmap, sample, filename, title)\n",
    "    print(f\"✅ Saved Grad-CAM: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
